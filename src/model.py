import torch
import torch.nn as nn
import torch.nn.functional as F
from collections import OrderedDict


class FactorizedConv(nn.Module):
    r"""
    Factorized $n \times n$ convolution into $n \times 1$ and $1 \times n$ convolution.
    Args:
        kernel_size (int): The larger size (n) of the convolution.
        in_channels (int): Number of input channels.
        out_channels (int): Number of output channels.
    """
    def __init__(self, kernel_size, in_channels, inner_channels, out_channels):
        super(FactorizedConv, self).__init__()
        h_kernel, h_padding = (1, kernel_size), (0, kernel_size // 2)
        v_kernel, v_padding = (kernel_size, 1), (kernel_size // 2, 0)

        self.horizontal_conv = nn.Conv2d(in_channels, inner_channels, kernel_size=h_kernel, padding=h_padding)
        self.vertical_conv = nn.Conv2d(in_channels, inner_channels, kernel_size=v_kernel, padding=v_padding)

        self.output_conv = nn.Sequential(OrderedDict([
            ('act in', nn.PReLU(2 * inner_channels)),
            ('conv', nn.Conv2d(2 * inner_channels, out_channels, kernel_size=(1, 1))),
            ('act out', nn.PReLU(out_channels))
        ]))

    def forward(self, x):
        x = torch.cat([self.vertical_conv(x), self.horizontal_conv(x)], dim=1)
        return self.output_conv(x)


class DenseBlock(nn.Module):
    r"""
    Dense Convolutional Block and attention block
    Args:
        in_channels (int): Number of block's input channels.
        inner_channels (int): Number of channels generated by the inner convolutions.
        out_channels (int): Number of block's output channels.
        num_dense_convs (int): Number of dense convolutions.
        scale_factor (bool): Use the scale factor as additional information.
        attention (bool): Use the attention block.
    """
    def __init__(self, in_channels, inner_channels, out_channels, num_dense_convs=2, scale_factor=False, attention=False):
        super(DenseBlock, self).__init__()
        self.out_channels = out_channels
        self.num_dense_convs = num_dense_convs
        self.use_scale_factor = scale_factor
        self.use_attention = attention

        # Base (input) convolution
        self.conv_0 = nn.Sequential(OrderedDict([
            ('conv', nn.Conv2d(in_channels, inner_channels, kernel_size=(3, 3), padding=(1, 1))),
            ('act', nn.PReLU(inner_channels))
        ]))

        list_dense_convs = []
        for i in range(1, 1 + num_dense_convs):
            list_dense_convs.append(
                nn.Sequential(OrderedDict([
                    ('conv', nn.Conv2d(in_channels + i * inner_channels, inner_channels, kernel_size=(3, 3), padding=(1, 1))),
                    ('act', nn.PReLU(inner_channels))
                ]))
            )

        self.dense_convs = nn.ModuleList(list_dense_convs)

        # Last convolution
        if scale_factor and not attention:
            in_channels_last_conv = in_channels + (num_dense_convs + 1) * inner_channels + 1
        else:
            in_channels_last_conv = in_channels + (num_dense_convs + 1) * inner_channels
        self.conv_1 = nn.Sequential(OrderedDict([
            ('conv', nn.Conv2d(in_channels_last_conv, out_channels, kernel_size=(1, 1))),
            ('act', nn.PReLU(out_channels))
        ]))

        if self.use_attention:
            linear_in_features = 1 + 16 * in_channels if scale_factor else 16 * in_channels
            self.pooling = nn.AdaptiveAvgPool2d((4, 4))
            self.attention_block = nn.Sequential(OrderedDict([
                ('linear 0', nn.Linear(linear_in_features, in_channels)),
                ('act 0', nn.PReLU(in_channels)),
                ('linear 1', nn.Linear(in_channels, out_channels)),
                ('act 1', nn.Sigmoid())
            ]))

    def forward(self, x, scale_factor=None):
        # Dense convolutions
        out = torch.cat([x, self.conv_0(x)], dim=1)
        for i in range(self.num_dense_convs):
            out = torch.cat([out, self.dense_convs[i](out)], dim=1)

        if self.use_attention:
            out = self.conv_1(out)
            att = self.pooling(out)
            b = att.size()[0]
            att = att.view(b, -1)
            if scale_factor is not None and self.use_scale_factor:      # Use attention and scale factor information.
                scale_factor = scale_factor.view(1, 1).repeat(b, 1)
                att = torch.cat([att, scale_factor], dim=1)

            att = self.attention_block(att)
            att = att.view(-1, self.out_channels, 1, 1)

            out = out * att + x
        else:
            if scale_factor is not None and self.use_scale_factor:      # Use scale factor in a feature map.
                b, _, h, w = out.size()
                scale_factor = scale_factor.view(1, 1, 1, 1).repeat(b, 1, h, w)
                out = torch.cat([out, scale_factor], dim=1)

            out = self.conv_1(out) + x

        return out


class Net(nn.Module):
    r"""
    Residual channel-spatial attention network for arbitrary scale super-resolution.
    """
    def __init__(self, **kwargs):
        super().__init__()
        base_filters = kwargs['base filters']
        num_dense_convs = kwargs['dense convolutions']
        self.use_scale_factor = kwargs['scale factor']
        self.use_attention = kwargs['attention']
        self.use_grl = kwargs['global residual learning']

        self.input_conv = nn.Sequential(OrderedDict([
            ('conv 0', nn.Conv2d(in_channels=3, out_channels=base_filters, kernel_size=(3, 3), padding=(1, 1))),
            ('act 0', nn.PReLU(base_filters)),
            ('conv 1', nn.Conv2d(in_channels=base_filters, out_channels=base_filters, kernel_size=(3, 3), padding=(1, 1))),
            ('act 1', nn.PReLU(base_filters))
        ]))

        self.block_0 = nn.ModuleList([
            DenseBlock(base_filters, base_filters, base_filters, num_dense_convs, self.use_scale_factor, self.use_attention),
            DenseBlock(base_filters, base_filters, base_filters, num_dense_convs, self.use_scale_factor, self.use_attention),
            DenseBlock(base_filters, base_filters, base_filters, num_dense_convs, self.use_scale_factor, self.use_attention),
            DenseBlock(base_filters, base_filters, base_filters, num_dense_convs, self.use_scale_factor, self.use_attention),
            FactorizedConv(3, 4 * base_filters, 4 * base_filters, base_filters)
        ])

        self.block_1 = nn.ModuleList([
            DenseBlock(base_filters, base_filters, base_filters, num_dense_convs, self.use_scale_factor, self.use_attention),
            DenseBlock(base_filters, base_filters, base_filters, num_dense_convs, self.use_scale_factor, self.use_attention),
            DenseBlock(base_filters, base_filters, base_filters, num_dense_convs, self.use_scale_factor, self.use_attention),
            DenseBlock(base_filters, base_filters, base_filters, num_dense_convs, self.use_scale_factor, self.use_attention),
            FactorizedConv(3, 4 * base_filters, 4 * base_filters, base_filters)
        ])

        self.block_2 = nn.ModuleList([
            DenseBlock(base_filters, base_filters, base_filters, num_dense_convs, self.use_scale_factor, self.use_attention),
            DenseBlock(base_filters, base_filters, base_filters, num_dense_convs, self.use_scale_factor, self.use_attention),
            DenseBlock(base_filters, base_filters, base_filters, num_dense_convs, self.use_scale_factor, self.use_attention),
            DenseBlock(base_filters, base_filters, base_filters, num_dense_convs, self.use_scale_factor, self.use_attention),
            FactorizedConv(3, 4 * base_filters, 4 * base_filters, base_filters)
        ])

        self.block_3 = nn.ModuleList([
            DenseBlock(base_filters, base_filters, base_filters, num_dense_convs, self.use_scale_factor, self.use_attention),
            DenseBlock(base_filters, base_filters, base_filters, num_dense_convs, self.use_scale_factor, self.use_attention),
            DenseBlock(base_filters, base_filters, base_filters, num_dense_convs, self.use_scale_factor, self.use_attention),
            DenseBlock(base_filters, base_filters, base_filters, num_dense_convs, self.use_scale_factor, self.use_attention),
            FactorizedConv(3, 4 * base_filters, 4 * base_filters, base_filters)
        ])

        self.block_4 = nn.ModuleList([
            DenseBlock(base_filters, base_filters, base_filters, num_dense_convs, self.use_scale_factor, self.use_attention),
            DenseBlock(base_filters, base_filters, base_filters, num_dense_convs, self.use_scale_factor, self.use_attention),
            DenseBlock(base_filters, base_filters, base_filters, num_dense_convs, self.use_scale_factor, self.use_attention),
            DenseBlock(base_filters, base_filters, base_filters, num_dense_convs, self.use_scale_factor, self.use_attention),
            FactorizedConv(3, 4 * base_filters, 4 * base_filters, base_filters)
        ])

        self.output_conv = nn.Sequential(OrderedDict([
            ('conv 0', nn.Conv2d(in_channels=base_filters, out_channels=base_filters, kernel_size=(3, 3), padding=(1, 1))),
            ('act 0', nn.PReLU(base_filters)),
            ('conv 1', nn.Conv2d(in_channels=base_filters, out_channels=3, kernel_size=(3, 3), padding=(1, 1))),
            ('act 1', nn.PReLU(3))
        ]))

    def forward(self, inputs, target_size=None):
        if target_size is None:
            target_size = torch.tensor([256, 256])  # Default value to compute MACs and parameters
        else:
            target_size = target_size[0]    # Consider only the first scale factor in batch

        v_size, h_size = inputs.size()[-2:]
        if self.use_scale_factor:
            scale = ((v_size / target_size[0] + h_size / target_size[1]) / 2.).to(inputs.device)
        else:
            scale = None
        # Low resolution
        outputs = self.input_conv(inputs)
        to_add = outputs

        # Block 0
        block = []
        for i in range(len(self.block_0) - 1):
            outputs = self.block_0[i](outputs, scale)
            block.append(outputs)
        outputs = self.block_0[-1](torch.cat(block, dim=1)) + to_add
        to_add = outputs

        # Block 1
        block = []
        for i in range(len(self.block_1) - 1):
            outputs = self.block_1[i](outputs, scale)
            block.append(outputs)
        outputs = self.block_1[-1](torch.cat(block, dim=1)) + to_add
        to_add = outputs

        # Block 2
        block = []
        for i in range(len(self.block_2) - 1):
            outputs = self.block_2[i](outputs, scale)
            block.append(outputs)
        outputs = self.block_2[-1](torch.cat(block, dim=1)) + to_add
        to_add = outputs

        # Block 3
        block = []
        for i in range(len(self.block_3) - 1):
            outputs = self.block_3[i](outputs, scale)
            block.append(outputs)
        outputs = self.block_3[-1](torch.cat(block, dim=1)) + to_add

        # Final section
        block = []
        outputs = F.interpolate(outputs, size=(target_size[0], target_size[1]), mode='bicubic', align_corners=False)
        to_add = outputs

        for i in range(len(self.block_4) - 1):
            outputs = self.block_4[i](outputs, scale)
            block.append(outputs)
        outputs = self.block_4[-1](torch.cat(block, dim=1)) + to_add

        if self.use_grl:
            outputs_hr = F.interpolate(inputs, size=(target_size[0], target_size[1]), mode='bicubic', align_corners=False)
            outputs_hr += self.output_conv(outputs)
        else:
            outputs_hr = self.output_conv(outputs)

        return outputs_hr

